# /performance/load-balancer-config.yaml
# Load balancing configuration for the AI Avatar Chat System.
# This configuration is designed for a cloud-native environment (e.g., Kubernetes with NGINX Ingress or a cloud load balancer).

apiVersion: v1
kind: ConfigMap
metadata:
  name: avatar-chat-lb-config
  namespace: avatar-chat-system
data:
  nginx.conf: |
    # NGINX load balancing configuration
    upstream avatar_chat_services {
      # Intelligent load balancing with least connections
      # This distributes requests to the server with the least number of active connections.
      least_conn;

      # Server pool for avatar chat backend services
      # These would be dynamically populated by a service discovery mechanism (e.g., Kubernetes Endpoints)
      server avatar-chat-service-1.default.svc.cluster.local:8080;
      server avatar-chat-service-2.default.svc.cluster.local:8080;
      server avatar-chat-service-3.default.svc.cluster.local:8080;
      # Add more servers as the service scales horizontally

      # Health Checks: NGINX Plus feature, but can be simulated with open-source NGINX
      # For open-source, external health checks would update this configuration.
    }

    server {
      listen 80;
      server_name chat.youravatardomain.com;

      location / {
        proxy_pass http://avatar_chat_services;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # Timeouts for handling slow clients and backend services
        proxy_connect_timeout 5s;
        proxy_send_timeout 10s;
        proxy_read_timeout 10s;

        # Retry mechanism for failover
        # If a request fails with these errors, it will be passed to the next server.
        proxy_next_upstream error timeout invalid_header http_502 http_503 http_504;
        proxy_next_upstream_tries 3; # Try up to 3 different servers
        proxy_next_upstream_timeout 10s; # Time limit for retries
      }

      # WebSocket support for real-time avatar streaming
      location /stream {
        proxy_pass http://avatar_chat_services/stream;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
        proxy_read_timeout 86400s; # Long timeout for persistent connections
      }
    }

# Cloud Load Balancer Configuration (Conceptual for AWS ELB / Google Cloud LB)
# This section is for documentation and would be configured in the cloud provider's console or via Terraform/CloudFormation.
cloud_load_balancer:
  name: avatar-chat-load-balancer
  listener_protocol: HTTPS
  instance_protocol: HTTP
  health_check:
    protocol: HTTP
    port: '8080'
    path: '/health'
    interval_seconds: 30
    timeout_seconds: 5
    healthy_threshold_count: 2
    unhealthy_threshold_count: 2
  stickiness:
    enabled: true
    cookie_duration: 3600 # 1 hour, for session persistence if needed
  failover:
    enabled: true
    cross_zone_load_balancing: true
  autoscaling_group:
    min_size: 2
    max_size: 10
    cpu_utilization_target: 75 # Target CPU utilization for scaling up